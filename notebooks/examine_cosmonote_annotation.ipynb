{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_data = readers.read_all_cosmo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_data[1].annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at loudness vs itself and audio\n",
    "\n",
    "def scoretime_to_clocktime(annotation, beats):\n",
    "    return [beats[annot] for annot in annotation]\n",
    "\n",
    "for piece in cosmo_data:\n",
    "    plt.figure()\n",
    "    # x,y = piece.loudness\n",
    "    # plt.plot(x,y)\n",
    "    plt.plot(piece.beats, piece.loudness)\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = np.nanmin(piece.loudness)\n",
    "    ymax = np.nanmax(piece.loudness)    \n",
    "    for annotator, annotation in piece.annotations.loudness:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    print(piece.piece_id)\n",
    "    plt.title(f\"Loudness curve and annotations—{piece.piece_id.replace('_',' ')}\")\n",
    "    plt.xlabel(\"Clock time\")\n",
    "    plt.ylabel(\"Loudness\")\n",
    "    plt.savefig(f\"output/loudness/{piece.piece_id}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scoring\n",
    "import itertools as itt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[[] for i in range(6)] for j in range(6)]\n",
    "\n",
    "for piece in cosmo_data:\n",
    "    #print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n",
    "    for (author1,annot1), (author2,annot2) in itt.permutations(piece.annotations.loudness, 2):\n",
    "        #print(author1,author2)\n",
    "        scores[int(author1)-1][int(author2)-1].append(scoring.fMeasure(annot1, annot2, tolerance=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([[len(x) for x in y] for y in scores])\n",
    "farray = np.array([[np.mean(x) for x in y] for y in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts)\n",
    "print(farray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresLoudAudio = [([],[]) for j in range(6)]\n",
    "\n",
    "for piece in cosmo_data:\n",
    "    #print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n",
    "    author_audio, annot_audio = piece.annotations.audio[0]\n",
    "    for author1,annot1 in piece.annotations.loudness:\n",
    "        #print(author1,author2)\n",
    "        fmeasure = scoring.fMeasure(annot1, annot_audio, tolerance=3)\n",
    "        scoresLoudAudio[int(author1)-1][0 if (author1 == author_audio) else 1].append(fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotator,(self_fs, other_fs) in enumerate(scoresLoudAudio):\n",
    "    print(f\"Annotator {annotator+1} scores:\")\n",
    "    print(f\"\\tself: {np.mean(self_fs)}\")\n",
    "    print(f\"\\tother: {np.mean(other_fs)}\")\n",
    "    print(f\"\\ttotal: {np.mean(self_fs+other_fs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at tempo vs itself and audio\n",
    "\n",
    "def scoretime_to_clocktime(annotation, beats):\n",
    "    return [beats[annot] for annot in annotation]\n",
    "\n",
    "for piece in cosmo_data:\n",
    "    plt.figure()\n",
    "    # x,y = piece.loudness\n",
    "    # plt.plot(x,y)\n",
    "    plt.plot(piece.beats, piece.tempo)\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = np.nanmin(piece.tempo)\n",
    "    ymax = np.nanmax(piece.tempo)    \n",
    "    for annotator, annotation in piece.annotations.tempo:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    print(piece.piece_id)\n",
    "    plt.title(f\"Tempo curve and annotations—{piece.piece_id.replace('_',' ')}\")\n",
    "    plt.xlabel(\"Clock time\")\n",
    "    plt.ylabel(\"Tempo\")\n",
    "    plt.savefig(f\"output/tempo/{piece.piece_id}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[[] for i in range(6)] for j in range(6)]\n",
    "\n",
    "for piece in cosmo_data:\n",
    "    #print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n",
    "    for (author1,annot1), (author2,annot2) in itt.permutations(piece.annotations.tempo, 2):\n",
    "        #print(author1,author2)\n",
    "        scores[int(author1)-1][int(author2)-1].append(scoring.fMeasure(annot1, annot2, tolerance=3))\n",
    "\n",
    "counts = np.array([[len(x) for x in y] for y in scores])\n",
    "farray = np.array([[np.mean(x) for x in y] for y in scores])\n",
    "print(counts)\n",
    "print(farray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresLoudAudio = [([],[]) for j in range(6)]\n",
    "\n",
    "for piece in cosmo_data:\n",
    "    #print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n",
    "    author_audio, annot_audio = piece.annotations.audio[0]\n",
    "    for author1,annot1 in piece.annotations.tempo:\n",
    "        #print(author1,author2)\n",
    "        fmeasure = scoring.fMeasure(annot1, annot_audio, tolerance=3)\n",
    "        scoresLoudAudio[int(author1)-1][0 if (author1 == author_audio) else 1].append(fmeasure)\n",
    "\n",
    "for annotator,(self_fs, other_fs) in enumerate(scoresLoudAudio):\n",
    "    print(f\"Annotator {annotator+1} scores:\")\n",
    "    print(f\"\\tself: {np.mean(self_fs)}\")\n",
    "    print(f\"\\tother: {np.mean(other_fs)}\")\n",
    "    print(f\"\\ttotal: {np.mean(self_fs+other_fs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynamic_computation as dc\n",
    "import default_priors\n",
    "import length_priors\n",
    "\n",
    "segmentations= {}\n",
    "for piece in cosmo_data:\n",
    "    arc_prior = default_priors.arcPriorTempo\n",
    "    length_prior_params = default_priors.lengthPriorParamsTempo\n",
    "    length_prior = length_priors.NormalLengthPrior(length_prior_params['mean'], \n",
    "                                                  length_prior_params['stddev']*2, \n",
    "                                                  range(len(piece.tempo)), \n",
    "                                                  length_prior_params['maxLength']*2)\n",
    "    posterior_marginals = dc.runAlphaBeta(piece.tempo[1:], arc_prior, length_prior)\n",
    "    segmentations[piece.piece_id] = posterior_marginals\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(piece.tempo, color=\"r\")  # Tempo input data\n",
    "    plt.ylim(0, 300)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n",
    "    plt.ylim(0, 1)\n",
    "    plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n",
    "    plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n",
    "    plt.title(f\"Tempo estimation vs annotation—{piece.piece_id.replace('_',' ')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_tempo = []\n",
    "f_audio = []\n",
    "for piece in cosmo_data:\n",
    "    estimation,_ = scoring.marginal2guess(segmentations[piece.piece_id], tolerance=3, threshold=.5)\n",
    "    f_tempo.append([scoring.fMeasure(estimation, annotation.boundaries, tolerance=3) for annotation in piece.annotations.tempo])\n",
    "    f_audio.append([scoring.fMeasure(estimation, annotation.boundaries, tolerance=3) for annotation in piece.annotations.audio])\n",
    "    print(piece.piece_id, f\"Tempo match: {f_tempo[-1]}\", f\"Audio match: {f_audio[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(l) for l in f_tempo]\n",
    "print(\"Mean: \", np.mean([np.mean(l) for l in f_tempo]))\n",
    "\n",
    "print(np.array(f_audio))\n",
    "print(\"Mean: \", np.mean(f_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for piece in cosmo_data:\n",
    "    posterior_marginals=[0,*segmentations[piece.piece_id]]\n",
    "    estimation,_ = scoring.marginal2guess([np.nan, *posterior_marginals], tolerance=3, threshold=.5)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(piece.tempo, color=\"r\")  # Tempo input data\n",
    "    plt.ylim(0, 1.1*np.nanmax(piece.tempo))\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = 0\n",
    "    ymax = np.nanmax(piece.tempo)*1.1    \n",
    "    for annotator, annotation in piece.annotations.tempo:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        plt.vlines(annotation, ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        plt.vlines(annotation, ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n",
    "    plt.ylim(0, 1)\n",
    "    # plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n",
    "    # plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n",
    "    plt.vlines(estimation, ymin=0, ymax=1, colors=\"k\", linestyles='dashed')\n",
    "    plt.savefig(f\"output/boundaries_tempo/{piece.piece_id}.pdf\")\n",
    "    plt.savefig(f\"output/boundaries_tempo/{piece.piece_id}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tempo = []\n",
    "f_audio = []\n",
    "for piece in cosmo_data:\n",
    "    estimation,_ = scoring.marginal2guess(segmentations[piece.piece_id], tolerance=3, threshold=.5)\n",
    "    f_tempo.append([scoring.fMeasure(scoretime_to_clocktime(estimation, piece.beats), scoretime_to_clocktime(annotation.boundaries, piece.beats), tolerance=3) for annotation in piece.annotations.tempo])\n",
    "    f_audio.append([scoring.fMeasure(scoretime_to_clocktime(estimation, piece.beats), scoretime_to_clocktime(annotation.boundaries, piece.beats), tolerance=3) for annotation in piece.annotations.audio])\n",
    "    print(piece.piece_id, f\"Tempo match: {f_tempo[-1]}\", f\"Audio match: {f_audio[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(l) for l in f_tempo]\n",
    "print(\"Mean: \", np.mean([np.mean(l) for l in f_tempo]))\n",
    "\n",
    "print(np.array(f_audio))\n",
    "print(\"Mean: \", np.mean(f_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"output/segmentations_2021_05_17.csv\", 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for excerpt, seg in segmentations.items():\n",
    "        writer.writerow([excerpt, *seg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynamic_computation as dc\n",
    "import default_priors\n",
    "import length_priors\n",
    "\n",
    "segmentations_loud= {}\n",
    "for piece in cosmo_data:\n",
    "    if piece.piece_id != \"excerpt_75\":\n",
    "        continue\n",
    "\n",
    "    arc_prior = default_priors.arcPriorLoud\n",
    "    length_prior_params = default_priors.lengthPriorParamsLoud\n",
    "    length_prior = length_priors.NormalLengthPrior(length_prior_params['mean'], \n",
    "                                                  length_prior_params['stddev']*2, \n",
    "                                                  range(len(piece.loudness)), \n",
    "                                                  length_prior_params['maxLength']*2)\n",
    "    posterior_marginals = dc.runAlphaBeta(piece.loudness, arc_prior, length_prior)\n",
    "    segmentations_loud[piece.piece_id] = posterior_marginals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise loudness segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for piece in cosmo_data:\n",
    "    posterior_marginals=segmentations_loud[piece.piece_id]\n",
    "    estimation,_ = scoring.marginal2guess([np.nan, *posterior_marginals], tolerance=3, threshold=.5)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(piece.loudness, color=\"r\")  # Tempo input data\n",
    "    plt.ylim(0, 1.1*np.nanmax(piece.loudness))\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = 0\n",
    "    ymax = np.nanmax(piece.loudness)*1.1    \n",
    "    for annotator, annotation in piece.annotations.loudness:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        plt.vlines(annotation, ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        plt.vlines(annotation, ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    \n",
    "    plt.ylabel(\"Loudness\")\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n",
    "    plt.ylim(0, 1)\n",
    "    # plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n",
    "    # plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n",
    "    plt.vlines(estimation, ymin=0, ymax=1, colors=\"k\", linestyles='dashed')\n",
    "    plt.title(f\"Loudness estimation vs annotation—{piece.piece_id.replace('_',' ')}\")\n",
    "    plt.xlabel(\"Beats\")\n",
    "    plt.ylabel(\"Likelihood of boundary\")\n",
    "    plt.savefig(f\"output/boundaries_loudness/{piece.piece_id}.pdf\")\n",
    "    plt.savefig(f\"output/boundaries_loudness/{piece.piece_id}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_loudness = []\n",
    "f_loudness_to_audio = []\n",
    "for piece in cosmo_data:\n",
    "    estimation,_ = scoring.marginal2guess(segmentations_loud[piece.piece_id], tolerance=3, threshold=.5)\n",
    "    f_loudness.append([scoring.fMeasure(estimation, annotation.boundaries, tolerance=3) for annotation in piece.annotations.loudness])\n",
    "    f_loudness_to_audio.append([scoring.fMeasure(estimation, annotation.boundaries, tolerance=3) for annotation in piece.annotations.audio])\n",
    "    print(piece.piece_id, f\"Loudness match: {f_loudness[-1]}\", f\"Audio match: {f_loudness_to_audio[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(l) for l in f_loudness]\n",
    "print(\"Mean: \", np.mean([np.mean(l) for l in f_loudness]))\n",
    "\n",
    "print(np.array(f_loudness_to_audio))\n",
    "print(\"Mean: \", np.mean(f_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for piece in cosmo_data:\n",
    "    if piece.piece_id != \"excerpt_75\":\n",
    "        continue\n",
    "    \n",
    "    posterior_marginals=segmentations_loud[piece.piece_id]\n",
    "    estimation,_ = scoring.marginal2guess([np.nan, *posterior_marginals], tolerance=3, threshold=.5)\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    plt.title(f\"Loudness annotation—{piece.piece_id.replace('_',' ')}\")\n",
    "    plt.xlabel(\"Beats\")\n",
    "    plt.ylabel(\"Loudness\")\n",
    "\n",
    "    ax1.plot(piece.loudness, color=\"r\")  # Tempo input data\n",
    "    plt.ylim(0, 1.1*np.nanmax(piece.loudness))\n",
    "    \n",
    "    fig.savefig(f\"output/buildup_example/1.png\", dpi=300)\n",
    "    fig.show()\n",
    "\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = 0\n",
    "    ymax = np.nanmax(piece.loudness)*1.1    \n",
    "    for annotator, annotation in piece.annotations.loudness:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        ax1.vlines(annotation, ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    \n",
    "    fig.savefig(f\"output/buildup_example/2.png\", dpi=300)\n",
    "    fig.show()\n",
    "\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        ax1.vlines(annotation, ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    \n",
    "    fig.savefig(f\"output/buildup_example/3.png\", dpi=300)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    plt.title(f\"Loudness estimation vs annotation—{piece.piece_id.replace('_',' ')}\")\n",
    "    ax2 = ax1.twinx()\n",
    "    plt.ylabel(\"Likelihood of boundary\")\n",
    "\n",
    "    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n",
    "    plt.ylim(0, 1)\n",
    "    # plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n",
    "    # plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n",
    "\n",
    "    fig.savefig(f\"output/buildup_example/4.png\", dpi=300)\n",
    "    fig.show()\n",
    "\n",
    "    ax2.vlines(estimation, ymin=0, ymax=1, colors=\"k\", linestyles='dashed')\n",
    "    \n",
    "    fig.savefig(f\"output/buildup_example/5.png\", dpi=300)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for piece in cosmo_data:\n",
    "    fig = plt.figure()\n",
    "    plt.title(f\"Tempo annotations—{piece.piece_id.replace('_',' ')}\")\n",
    "    plt.ylabel(\"Tempo (bpm)\")\n",
    "    plt.xlabel(\"Clocktime (s)\")\n",
    "    plt.plot(piece.beats, piece.tempo)\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = np.nanmin(piece.tempo)\n",
    "    ymax = np.nanmax(piece.tempo)    \n",
    "    for annotator, annotation in piece.annotations.tempo:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    fig.savefig(f\"output/pure_annot/{piece.piece_id}_tempo.pdf\", dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.title(f\"Loudness annotations—{piece.piece_id.replace('_',' ')}\")\n",
    "    plt.ylabel(\"Loudness\")\n",
    "    plt.xlabel(\"Clocktime (s)\")\n",
    "    plt.plot(piece.beats, piece.loudness)\n",
    "    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n",
    "    ymin = np.nanmin(piece.loudness)\n",
    "    ymax = np.nanmax(piece.loudness)    \n",
    "    for annotator, annotation in piece.annotations.loudness:\n",
    "        yymin = ymin + (ymax-ymin)* (int(annotator)-1)/6\n",
    "        yymax = ymin + (ymax-ymin)* (int(annotator))/6\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n",
    "    for annotator, annotation in piece.annotations.audio:\n",
    "        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n",
    "    fig.savefig(f\"output/pure_annot/{piece.piece_id}_loudness.pdf\", dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = [[] for i in range(6)]\n",
    "for piece in cosmo_data:\n",
    "    ann_id = int(piece.annotations.audio[0].author) - 1\n",
    "    clocktimeAudio = scoretime_to_clocktime(piece.annotations.audio[0].boundaries, piece.beats)\n",
    "    #means[ann_id].extend(list(np.diff(clocktimeAudio)))\n",
    "    deltas[ann_id].extend(np.diff(clocktimeAudio))\n",
    "print([np.mean(x) for x in deltas],'\\n',[np.std(x) for x in deltas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)",
   "name": "python382jvsc74a57bd0fe342846219a16f257363f855d4f4aa015c41a10a3fd9707ee27a7e2be886740"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
