{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import csv\n","import itertools as itt\n","\n","from bayes_arcs import default_priors\n","from bayes_arcs import dynamic_computation as dc\n","import length_priors\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import readers\n","import scoring\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cosmo_data = readers.read_all_cosmo_data()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cosmo_data[1].annotations\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Look at loudness vs itself and audio\n","\n","def scoretime_to_clocktime(annotation, beats):\n","    return [beats[annot] for annot in annotation]\n","\n","\n","for piece in cosmo_data:\n","    plt.figure()\n","    # x,y = piece.loudness\n","    # plt.plot(x,y)\n","    plt.plot(piece.beats, piece.loudness)\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = np.nanmin(piece.loudness)\n","    ymax = np.nanmax(piece.loudness)\n","    for annotator, annotation in piece.annotations.loudness:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats),\n","                   ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","    for annotator, annotation in piece.annotations.audio:\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin,\n","                   ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","    print(piece.piece_id)\n","    plt.title(f\"Loudness curve and annotations—{piece.piece_id.replace('_',' ')}\")\n","    plt.xlabel(\"Clock time\")\n","    plt.ylabel(\"Loudness\")\n","    plt.savefig(f\"output/loudness/{piece.piece_id}.pdf\")\n","    plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores = [[[] for i in range(6)] for j in range(6)]\n","\n","for piece in cosmo_data:\n","    # print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n","    for (author1, annot1), (author2, annot2) in itt.permutations(piece.annotations.loudness, 2):\n","        # print(author1,author2)\n","        scores[int(author1)-1][int(author2)-1].append(scoring.f_measure(annot1, annot2, tolerance=3))\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["counts = np.array([[len(x) for x in y] for y in scores])\n","farray = np.array([[np.mean(x) for x in y] for y in scores])\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(counts)\n","print(farray)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores_loud_audio = [([], []) for j in range(6)]\n","\n","for piece in cosmo_data:\n","    # print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n","    author_audio, annot_audio = piece.annotations.audio[0]\n","    for author1, annot1 in piece.annotations.loudness:\n","        # print(author1,author2)\n","        fmeasure = scoring.f_measure(annot1, annot_audio, tolerance=3)\n","        scores_loud_audio[int(author1)-1][0 if (author1 == author_audio) else 1].append(fmeasure)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for annotator, (self_fs, other_fs) in enumerate(scores_loud_audio):\n","    print(f\"Annotator {annotator+1} scores:\")\n","    print(f\"\\tself: {np.mean(self_fs)}\")\n","    print(f\"\\tother: {np.mean(other_fs)}\")\n","    print(f\"\\ttotal: {np.mean(self_fs+other_fs)}\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Look at tempo vs itself and audio\n","\n","for piece in cosmo_data:\n","    plt.figure()\n","    # x,y = piece.loudness\n","    # plt.plot(x,y)\n","    plt.plot(piece.beats, piece.tempo)\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = np.nanmin(piece.tempo)\n","    ymax = np.nanmax(piece.tempo)\n","    for annotator, annotation in piece.annotations.tempo:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats),\n","                   ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","    for annotator, annotation in piece.annotations.audio:\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin,\n","                   ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","    print(piece.piece_id)\n","    plt.title(f\"Tempo curve and annotations—{piece.piece_id.replace('_',' ')}\")\n","    plt.xlabel(\"Clock time\")\n","    plt.ylabel(\"Tempo\")\n","    plt.savefig(f\"output/tempo/{piece.piece_id}.pdf\")\n","    plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores = [[[] for i in range(6)] for j in range(6)]\n","\n","for piece in cosmo_data:\n","    # print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n","    for (author1, annot1), (author2, annot2) in itt.permutations(piece.annotations.tempo, 2):\n","        # print(author1,author2)\n","        scores[int(author1)-1][int(author2)-1].append(scoring.f_measure(annot1, annot2, tolerance=3))\n","\n","counts = np.array([[len(x) for x in y] for y in scores])\n","farray = np.array([[np.mean(x) for x in y] for y in scores])\n","print(counts)\n","print(farray)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores_loud_audio = [([], []) for j in range(6)]\n","\n","for piece in cosmo_data:\n","    # print([(piece.piece_id, author) for author,_ in piece.annotations.loudness])\n","    author_audio, annot_audio = piece.annotations.audio[0]\n","    for author1, annot1 in piece.annotations.tempo:\n","        # print(author1,author2)\n","        fmeasure = scoring.f_measure(annot1, annot_audio, tolerance=3)\n","        scores_loud_audio[int(author1)-1][0 if (author1 == author_audio) else 1].append(fmeasure)\n","\n","for annotator, (self_fs, other_fs) in enumerate(scores_loud_audio):\n","    print(f\"Annotator {annotator+1} scores:\")\n","    print(f\"\\tself: {np.mean(self_fs)}\")\n","    print(f\"\\tother: {np.mean(other_fs)}\")\n","    print(f\"\\ttotal: {np.mean(self_fs+other_fs)}\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","segmentations = {}\n","for piece in cosmo_data:\n","    arc_prior = default_priors.arc_prior_tempo\n","    length_prior_params = default_priors.length_prior_params_tempo\n","    length_prior = length_priors.NormalLengthPrior(length_prior_params['mean'],\n","                                                   length_prior_params['stddev']*2,\n","                                                   range(len(piece.tempo)),\n","                                                   length_prior_params['maxLength']*2)\n","    posterior_marginals = dc.run_alpha_beta(piece.tempo[1:], arc_prior, length_prior)\n","    segmentations[piece.piece_id] = posterior_marginals\n","\n","    fig, ax1 = plt.subplots()\n","    ax1.plot(piece.tempo, color=\"r\")  # Tempo input data\n","    plt.ylim(0, 300)\n","\n","    ax2 = ax1.twinx()\n","\n","    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n","    plt.ylim(0, 1)\n","    plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n","    plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n","    plt.title(f\"Tempo estimation vs annotation—{piece.piece_id.replace('_',' ')}\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f_tempo = []\n","f_audio = []\n","for piece in cosmo_data:\n","    estimation, _ = scoring.marginal2guess(segmentations[piece.piece_id], tolerance=3, threshold=.5)\n","    f_tempo.append([scoring.f_measure(estimation, annotation.boundaries, tolerance=3)\n","                   for annotation in piece.annotations.tempo])\n","    f_audio.append([scoring.f_measure(estimation, annotation.boundaries, tolerance=3)\n","                   for annotation in piece.annotations.audio])\n","    print(piece.piece_id, f\"Tempo match: {f_tempo[-1]}\", f\"Audio match: {f_audio[-1]}\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["[print(value) for value in f_tempo]\n","print(\"Mean: \", np.mean([np.mean(value) for value in f_tempo]))\n","\n","print(np.array(f_audio))\n","print(\"Mean: \", np.mean(f_audio))\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for piece in cosmo_data:\n","    posterior_marginals = [0, *segmentations[piece.piece_id]]\n","    estimation, _ = scoring.marginal2guess([np.nan, *posterior_marginals], tolerance=3, threshold=.5)\n","    fig, ax1 = plt.subplots()\n","    ax1.plot(piece.tempo, color=\"r\")  # Tempo input data\n","    plt.ylim(0, 1.1*np.nanmax(piece.tempo))\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = 0\n","    ymax = np.nanmax(piece.tempo)*1.1\n","    for annotator, annotation in piece.annotations.tempo:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        plt.vlines(annotation, ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","    for annotator, annotation in piece.annotations.audio:\n","        plt.vlines(annotation, ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","    ax2 = ax1.twinx()\n","\n","    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n","    plt.ylim(0, 1)\n","    # plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n","    # plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n","    plt.vlines(estimation, ymin=0, ymax=1, colors=\"k\", linestyles='dashed')\n","    plt.savefig(f\"output/boundaries_tempo/{piece.piece_id}.pdf\")\n","    plt.savefig(f\"output/boundaries_tempo/{piece.piece_id}.png\")\n","    plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f_tempo = []\n","f_audio = []\n","for piece in cosmo_data:\n","    estimation, _ = scoring.marginal2guess(segmentations[piece.piece_id], tolerance=3, threshold=.5)\n","    f_tempo.append([scoring.f_measure(scoretime_to_clocktime(estimation, piece.beats), scoretime_to_clocktime(\n","        annotation.boundaries, piece.beats), tolerance=3) for annotation in piece.annotations.tempo])\n","    f_audio.append([scoring.f_measure(scoretime_to_clocktime(estimation, piece.beats), scoretime_to_clocktime(\n","        annotation.boundaries, piece.beats), tolerance=3) for annotation in piece.annotations.audio])\n","    print(piece.piece_id, f\"Tempo match: {f_tempo[-1]}\", f\"Audio match: {f_audio[-1]}\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["[print(value) for value in f_tempo]\n","print(\"Mean: \", np.mean([np.mean(value) for value in f_tempo]))\n","\n","print(np.array(f_audio))\n","print(\"Mean: \", np.mean(f_audio))\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","with open(\"output/segmentations_2021_05_17.csv\", 'w') as csv_file:\n","    writer = csv.writer(csv_file)\n","    for excerpt, seg in segmentations.items():\n","        writer.writerow([excerpt, *seg])\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","segmentations_loud = {}\n","for piece in cosmo_data:\n","    if piece.piece_id != \"excerpt_75\":\n","        continue\n","\n","    arc_prior = default_priors.arc_prior_loud\n","    length_prior_params = default_priors.length_prior_params_loud\n","    length_prior = length_priors.NormalLengthPrior(length_prior_params['mean'],\n","                                                   length_prior_params['stddev']*2,\n","                                                   range(len(piece.loudness)),\n","                                                   length_prior_params['maxLength']*2)\n","    posterior_marginals = dc.run_alpha_beta(piece.loudness, arc_prior, length_prior)\n","    segmentations_loud[piece.piece_id] = posterior_marginals\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Visualise loudness segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for piece in cosmo_data:\n","    posterior_marginals = segmentations_loud[piece.piece_id]\n","    estimation, _ = scoring.marginal2guess([np.nan, *posterior_marginals], tolerance=3, threshold=.5)\n","    fig, ax1 = plt.subplots()\n","    ax1.plot(piece.loudness, color=\"r\")  # Tempo input data\n","    plt.ylim(0, 1.1*np.nanmax(piece.loudness))\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = 0\n","    ymax = np.nanmax(piece.loudness)*1.1\n","    for annotator, annotation in piece.annotations.loudness:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        plt.vlines(annotation, ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","    for annotator, annotation in piece.annotations.audio:\n","        plt.vlines(annotation, ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","\n","    plt.ylabel(\"Loudness\")\n","    ax2 = ax1.twinx()\n","\n","    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n","    plt.ylim(0, 1)\n","    # plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n","    # plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n","    plt.vlines(estimation, ymin=0, ymax=1, colors=\"k\", linestyles='dashed')\n","    plt.title(f\"Loudness estimation vs annotation—{piece.piece_id.replace('_',' ')}\")\n","    plt.xlabel(\"Beats\")\n","    plt.ylabel(\"Likelihood of boundary\")\n","    plt.savefig(f\"output/boundaries_loudness/{piece.piece_id}.pdf\")\n","    plt.savefig(f\"output/boundaries_loudness/{piece.piece_id}.png\")\n","    plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f_loudness = []\n","f_loudness_to_audio = []\n","for piece in cosmo_data:\n","    estimation, _ = scoring.marginal2guess(segmentations_loud[piece.piece_id], tolerance=3, threshold=.5)\n","    f_loudness.append([scoring.f_measure(estimation, annotation.boundaries, tolerance=3)\n","                      for annotation in piece.annotations.loudness])\n","    f_loudness_to_audio.append([scoring.f_measure(estimation, annotation.boundaries, tolerance=3)\n","                               for annotation in piece.annotations.audio])\n","    print(piece.piece_id, f\"Loudness match: {f_loudness[-1]}\", f\"Audio match: {f_loudness_to_audio[-1]}\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["[print(value) for value in f_loudness]\n","print(\"Mean: \", np.mean([np.mean(value) for value in f_loudness]))\n","\n","print(np.array(f_loudness_to_audio))\n","print(\"Mean: \", np.mean(f_audio))\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for piece in cosmo_data:\n","    if piece.piece_id != \"excerpt_75\":\n","        continue\n","\n","    posterior_marginals = segmentations_loud[piece.piece_id]\n","    estimation, _ = scoring.marginal2guess([np.nan, *posterior_marginals], tolerance=3, threshold=.5)\n","    fig, ax1 = plt.subplots(figsize=(8, 5))\n","    plt.title(f\"Loudness annotation—{piece.piece_id.replace('_',' ')}\")\n","    plt.xlabel(\"Beats\")\n","    plt.ylabel(\"Loudness\")\n","\n","    ax1.plot(piece.loudness, color=\"r\")  # Tempo input data\n","    plt.ylim(0, 1.1*np.nanmax(piece.loudness))\n","\n","    fig.savefig(\"output/buildup_example/1.png\", dpi=300)\n","    fig.show()\n","\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = 0\n","    ymax = np.nanmax(piece.loudness)*1.1\n","    for annotator, annotation in piece.annotations.loudness:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        ax1.vlines(annotation, ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","\n","    fig.savefig(\"output/buildup_example/2.png\", dpi=300)\n","    fig.show()\n","\n","    for annotator, annotation in piece.annotations.audio:\n","        ax1.vlines(annotation, ymin=ymin, ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","\n","    fig.savefig(\"output/buildup_example/3.png\", dpi=300)\n","    fig.show()\n","\n","    plt.title(f\"Loudness estimation vs annotation—{piece.piece_id.replace('_',' ')}\")\n","    ax2 = ax1.twinx()\n","    plt.ylabel(\"Likelihood of boundary\")\n","\n","    ax2.plot(posterior_marginals, 'k')  # Posterior Marginals\n","    plt.ylim(0, 1)\n","    # plt.vlines(piece.annotations.audio[0].boundaries, ymin=0, ymax=1, colors=\"r\", linestyle='dotted')  # Tempo seg\n","    # plt.vlines(piece.annotations.tempo[0].boundaries, ymin=0, ymax=1, colors=\"b\", linestyle='dotted')  # Dyn seg\n","\n","    fig.savefig(\"output/buildup_example/4.png\", dpi=300)\n","    fig.show()\n","\n","    ax2.vlines(estimation, ymin=0, ymax=1, colors=\"k\", linestyles='dashed')\n","\n","    fig.savefig(\"output/buildup_example/5.png\", dpi=300)\n","    fig.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for piece in cosmo_data:\n","    fig = plt.figure()\n","    plt.title(f\"Tempo annotations—{piece.piece_id.replace('_',' ')}\")\n","    plt.ylabel(\"Tempo (bpm)\")\n","    plt.xlabel(\"Clocktime (s)\")\n","    plt.plot(piece.beats, piece.tempo)\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = np.nanmin(piece.tempo)\n","    ymax = np.nanmax(piece.tempo)\n","    for annotator, annotation in piece.annotations.tempo:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats),\n","                   ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","    for annotator, annotation in piece.annotations.audio:\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin,\n","                   ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","    fig.savefig(f\"output/pure_annot/{piece.piece_id}_tempo.pdf\", dpi=300)\n","    plt.close(fig)\n","\n","    fig = plt.figure()\n","    plt.title(f\"Loudness annotations—{piece.piece_id.replace('_',' ')}\")\n","    plt.ylabel(\"Loudness\")\n","    plt.xlabel(\"Clocktime (s)\")\n","    plt.plot(piece.beats, piece.loudness)\n","    colors = [\"k\", \"g\", \"b\", \"r\", \"c\", \"m\"]\n","    ymin = np.nanmin(piece.loudness)\n","    ymax = np.nanmax(piece.loudness)\n","    for annotator, annotation in piece.annotations.loudness:\n","        yymin = ymin + (ymax-ymin) * (int(annotator)-1)/6\n","        yymax = ymin + (ymax-ymin) * (int(annotator))/6\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats),\n","                   ymin=yymin, ymax=yymax, colors=colors[int(annotator)-1])\n","    for annotator, annotation in piece.annotations.audio:\n","        plt.vlines(scoretime_to_clocktime(annotation, piece.beats), ymin=ymin,\n","                   ymax=ymax, colors=colors[int(annotator)-1], linestyles='dotted')\n","    fig.savefig(f\"output/pure_annot/{piece.piece_id}_loudness.pdf\", dpi=300)\n","    plt.close(fig)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["deltas = [[] for i in range(6)]\n","for piece in cosmo_data:\n","    ann_id = int(piece.annotations.audio[0].author) - 1\n","    clocktime_audio = scoretime_to_clocktime(piece.annotations.audio[0].boundaries, piece.beats)\n","    # means[ann_id].extend(list(np.diff(clocktimeAudio)))\n","    deltas[ann_id].extend(np.diff(clocktime_audio))\n","print([np.mean(x) for x in deltas], '\\n', [np.std(x) for x in deltas])\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}